# LLAMA_3_with_Hugging_Face
LLAMA_3_with_Hugging_Face

Things to do :- 

1) Install the requirements 
2) Import the liabraries 
3) HF Account Configuration
4) Give the model name
5) Configure for Quantization
6) Loading the tockenizer and the model
7) Creating the pipeline / text generator
8) Create a function to get a response where the user can pass the prompt and our model will give the response. 
